{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78a7ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def set_random_seed(seed=42):\n",
    "    \"\"\"\n",
    "    랜덤 시드 고정\n",
    "    :param seed: 고정할 랜덤 시드 값 (기본값: 42)\n",
    "    \"\"\"\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # Python 랜덤 시드\n",
    "    random.seed(seed)                         # random 모듈 랜덤 시드\n",
    "    np.random.seed(seed)                      # NumPy 랜덤 시드\n",
    "    tf.random.set_seed(seed)                  # TensorFlow 랜덤 시드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abb3c4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (13284, 96, 6)\n",
      "y_train shape: (13284, 720, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Dense, Layer, Embedding, Add, LayerNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# CSV 파일 로드\n",
    "file_path = \"./ETTh1.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 날짜를 datetime으로 변환 후 인덱스 설정\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df = df.set_index(\"date\")\n",
    "\n",
    "# 입력에 사용할 Feature와 출력에 사용할 Target 분리\n",
    "input_features = ['HUFL', 'HULL', 'MUFL', 'MULL', 'LUFL', 'LULL']  # 입력 특성 (6개)\n",
    "target_feature = ['OT']  # 출력 대상 (1개)\n",
    "\n",
    "# 입력 및 출력 데이터 준비\n",
    "X_raw = df[input_features].values  # 입력 데이터\n",
    "y_raw = df[target_feature].values  # 출력 데이터\n",
    "\n",
    "# 데이터 정규화 (MinMaxScaler)\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X_raw)  # 입력 데이터 정규화\n",
    "y_scaled = scaler_y.fit_transform(y_raw)  # 출력 데이터 정규화\n",
    "\n",
    "# 입력 및 출력 시퀀스 길이 설정\n",
    "input_length = 96  # 입력 시퀀스 길이\n",
    "output_length = 720  # 예측 시퀀스 길이 96, 192, 336, 720\n",
    "\n",
    "# 입력 및 출력 시퀀스 생성\n",
    "X, y = [], []\n",
    "for i in range(len(X_scaled) - input_length - output_length + 1):\n",
    "    X.append(X_scaled[i : i + input_length])  # 입력 시퀀스\n",
    "    y.append(y_scaled[i + input_length : i + input_length + output_length])  # 출력 시퀀스\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 결과 확인\n",
    "print(f\"X_train shape: {X_train.shape}\")  # (batch_size, input_length, input_features)\n",
    "print(f\"y_train shape: {y_train.shape}\")  # (batch_size, output_length, target_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7990ed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncodingLayer(Layer):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncodingLayer, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def call(self, inputs):\n",
    "        seq_len = tf.shape(inputs)[1]\n",
    "        position = tf.cast(tf.range(0, seq_len)[:, tf.newaxis], tf.float32)  # (seq_len, 1)\n",
    "        div_term = tf.exp(tf.range(0, self.d_model, 2, dtype=tf.float32) * -(tf.math.log(10000.0) / self.d_model))  # (d_model/2)\n",
    "\n",
    "        # Calculate sinusoidal positional encoding\n",
    "        angle_rads = position * div_term  # Broadcasting (seq_len, d_model/2)\n",
    "        sin_encoding = tf.sin(angle_rads)  # (seq_len, d_model/2)\n",
    "        cos_encoding = tf.cos(angle_rads)  # (seq_len, d_model/2)\n",
    "\n",
    "        # Combine sin and cos encodings\n",
    "        pe = tf.concat([sin_encoding, cos_encoding], axis=-1)  # (seq_len, d_model)\n",
    "        pe = tf.expand_dims(pe, axis=0)  # Add batch dimension (1, seq_len, d_model)\n",
    "\n",
    "        return inputs + pe[:, :seq_len, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e9e4bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNPositionalEncodingLayer(Layer):\n",
    "    def __init__(self, d_model, num_cnn_layers=3, kernel_size=3, activation=\"relu\"):\n",
    "        super(CNNPositionalEncodingLayer, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_cnn_layers = num_cnn_layers\n",
    "        self.kernel_size = kernel_size\n",
    "        self.activation = activation\n",
    "\n",
    "        # CNN 레이어 쌓기\n",
    "        self.conv_layers = [\n",
    "            tf.keras.layers.Conv1D(\n",
    "                filters=d_model,\n",
    "                kernel_size=self.kernel_size,\n",
    "                padding=\"same\",\n",
    "                activation=self.activation\n",
    "            )\n",
    "            for _ in range(self.num_cnn_layers)\n",
    "        ]\n",
    "\n",
    "        # 마지막 1D CNN 레이어로 d_model 출력 보장\n",
    "        self.final_conv = tf.keras.layers.Conv1D(\n",
    "            filters=d_model,\n",
    "            kernel_size=1,\n",
    "            padding=\"same\",\n",
    "            activation=None\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for conv in self.conv_layers:\n",
    "            x = conv(x)\n",
    "\n",
    "        # 마지막 CNN 레이어로 d_model 크기의 출력 생성\n",
    "        pos_encoding = self.final_conv(x)\n",
    "\n",
    "        # 포지셔널 인코딩 추가\n",
    "        return inputs + pos_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622ac24a",
   "metadata": {},
   "source": [
    "# Vanila Transformer(encoder-only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79a176c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transformer(input_length, input_dim, output_length, d_model, num_heads, num_layers, pos = 0):\n",
    "    # 입력 레이어\n",
    "    inputs = Input(shape=(input_length, input_dim))  # (batch_size, input_length, input_dim)\n",
    "    x = Dense(d_model)(inputs)  # Feature 차원을 input_dim → d_model로 변환\n",
    "    \n",
    "    # 포지셔널 인코딩 방식 선택\n",
    "    if pos == 0:\n",
    "        x = PositionalEncodingLayer(d_model)(x)  # 기존 Positional Encoding 추가\n",
    "    elif pos == 1:\n",
    "        x = CNNPositionalEncodingLayer(d_model)(x)  # CNN 기반 Positional Encoding 추가\n",
    "\n",
    "    # Transformer 블록\n",
    "    for _ in range(num_layers):\n",
    "        # Multi-Head Attention\n",
    "        attention_output = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(x, x)\n",
    "        attention_output = tf.keras.layers.Dropout(0.1)(attention_output)\n",
    "        attention_output = Add()([x, attention_output])  # Residual Connection\n",
    "        attention_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention_output)\n",
    "\n",
    "        # Feed Forward Network (FFN)\n",
    "        ffn_output = Dense(d_model * 4, activation=\"relu\")(attention_output)\n",
    "        ffn_output = Dense(d_model)(ffn_output)\n",
    "        ffn_output = tf.keras.layers.Dropout(0.1)(ffn_output)\n",
    "        x = Add()([attention_output, ffn_output])  # Residual Connection\n",
    "        x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "    # 출력 레이어\n",
    "    # 입력 시퀀스 길이를 출력 시퀀스 길이로 확장\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)  # 시간축 제거 (batch_size, d_model)\n",
    "    x = tf.keras.layers.RepeatVector(output_length)(x)  # (batch_size, output_length, d_model)\n",
    "    x = Dense(d_model, activation=\"relu\")(x)  # 중간 레이어\n",
    "    outputs = Dense(1, activation=\"linear\")(x)  # 최종 출력 (batch_size, output_length, 1)\n",
    "\n",
    "    return Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9aee957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 96, 6)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 96, 64)       448         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cnn_positional_encoding_layer_2 (None, 96, 64)       41216       dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_12 (MultiH (None, 96, 64)       66368       cnn_positional_encoding_layer_2[0\n",
      "                                                                 cnn_positional_encoding_layer_2[0\n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 96, 64)       0           multi_head_attention_12[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 96, 64)       0           cnn_positional_encoding_layer_2[0\n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_22 (LayerNo (None, 96, 64)       128         add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 96, 256)      16640       layer_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 96, 64)       16448       dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 96, 64)       0           dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 96, 64)       0           layer_normalization_22[0][0]     \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_23 (LayerNo (None, 96, 64)       128         add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_13 (MultiH (None, 96, 64)       66368       layer_normalization_23[0][0]     \n",
      "                                                                 layer_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 96, 64)       0           multi_head_attention_13[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 96, 64)       0           layer_normalization_23[0][0]     \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_24 (LayerNo (None, 96, 64)       128         add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 96, 256)      16640       layer_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 96, 64)       16448       dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 96, 64)       0           dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 96, 64)       0           layer_normalization_24[0][0]     \n",
      "                                                                 dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_25 (LayerNo (None, 96, 64)       128         add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 64)           0           layer_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_5 (RepeatVector)  (None, 720, 64)      0           global_average_pooling1d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 720, 64)      4160        repeat_vector_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 720, 1)       65          dense_37[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 245,313\n",
      "Trainable params: 245,313\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "set_random_seed()\n",
    "\n",
    "# 모델 생성\n",
    "input_dim = X_train.shape[-1]   # 입력 데이터의 특성 차원\n",
    "\n",
    "d_model = 64\n",
    "num_heads = 4   # Multi-Head Attention에서의 head 개수\n",
    "num_layers = 2  # Transformer 블록의 레이어 수\n",
    "pos = 1\n",
    "\n",
    "# Transformer 모델 생성\n",
    "transformer_model = build_transformer(input_length, input_dim, output_length, d_model, num_heads, num_layers, pos)\n",
    "\n",
    "# 모델 컴파일\n",
    "transformer_model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "transformer_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf074bd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "52/52 [==============================] - 3s 31ms/step - loss: 0.1573 - mae: 0.2370 - val_loss: 0.0266 - val_mae: 0.1264\n",
      "Epoch 2/20\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0262 - mae: 0.1268 - val_loss: 0.0259 - val_mae: 0.1250\n",
      "Epoch 3/20\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.0253 - mae: 0.1251 - val_loss: 0.0253 - val_mae: 0.1279\n",
      "Epoch 4/20\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0234 - mae: 0.1210 - val_loss: 0.0216 - val_mae: 0.1151\n",
      "Epoch 5/20\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0208 - mae: 0.1129 - val_loss: 0.0176 - val_mae: 0.1007\n",
      "Epoch 6/20\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0150 - mae: 0.0954 - val_loss: 0.0144 - val_mae: 0.0918\n",
      "Epoch 7/20\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0124 - mae: 0.0864 - val_loss: 0.0112 - val_mae: 0.0825\n",
      "Epoch 8/20\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0108 - mae: 0.0802 - val_loss: 0.0095 - val_mae: 0.0743\n",
      "Epoch 9/20\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0096 - mae: 0.0762 - val_loss: 0.0105 - val_mae: 0.0804\n",
      "Epoch 10/20\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0087 - mae: 0.0725 - val_loss: 0.0074 - val_mae: 0.0664\n",
      "Epoch 11/20\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0082 - mae: 0.0704 - val_loss: 0.0092 - val_mae: 0.0737\n",
      "Epoch 12/20\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0075 - mae: 0.0667 - val_loss: 0.0061 - val_mae: 0.0603\n",
      "Epoch 13/20\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.0064 - mae: 0.0620 - val_loss: 0.0067 - val_mae: 0.0628\n",
      "Epoch 14/20\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.0062 - mae: 0.0610 - val_loss: 0.0058 - val_mae: 0.0585\n",
      "Epoch 15/20\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0059 - mae: 0.0593 - val_loss: 0.0054 - val_mae: 0.0565\n",
      "Epoch 16/20\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.0059 - mae: 0.0595 - val_loss: 0.0057 - val_mae: 0.0580\n",
      "Epoch 17/20\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0057 - mae: 0.0587 - val_loss: 0.0057 - val_mae: 0.0584\n",
      "Epoch 18/20\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.0053 - mae: 0.0566 - val_loss: 0.0058 - val_mae: 0.0592\n",
      "Epoch 19/20\n",
      "52/52 [==============================] - 1s 23ms/step - loss: 0.0053 - mae: 0.0562 - val_loss: 0.0049 - val_mae: 0.0545\n",
      "Epoch 20/20\n",
      "52/52 [==============================] - 1s 22ms/step - loss: 0.0052 - mae: 0.0562 - val_loss: 0.0049 - val_mae: 0.0539\n",
      "104/104 [==============================] - 1s 7ms/step - loss: 0.0049 - mae: 0.0539\n",
      "Test Loss: 0.004863376263529062, Test MAE: 0.05393539369106293\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "history = transformer_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=256)\n",
    "\n",
    "# 모델 평가\n",
    "loss, mae = transformer_model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}, Test MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77669fd8",
   "metadata": {},
   "source": [
    "# Vanila Transformer(encoder-decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f00bd409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Add, LayerNormalization, MultiHeadAttention, Dropout, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_transformer(input_length, input_dim, output_length, d_model, num_heads, num_layers, pos=0):\n",
    "    # 인코더 입력\n",
    "    encoder_inputs = Input(shape=(input_length, input_dim))  # (batch_size, input_length, input_dim)\n",
    "    x = Dense(d_model)(encoder_inputs)  # Feature 차원을 input_dim → d_model로 변환\n",
    "    \n",
    "    # 포지셔널 인코딩 추가\n",
    "    if pos == 0:\n",
    "        x = PositionalEncodingLayer(d_model)(x)\n",
    "    elif pos == 1:\n",
    "        x = CNNPositionalEncodingLayer(d_model)(x)\n",
    "\n",
    "    # 인코더 블록\n",
    "    for _ in range(num_layers):\n",
    "        # Self-Attention\n",
    "        attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(x, x)\n",
    "        attention_output = Dropout(0.1)(attention_output)\n",
    "        attention_output = Add()([x, attention_output])  # Residual Connection\n",
    "        attention_output = LayerNormalization(epsilon=1e-6)(attention_output)\n",
    "\n",
    "        # Feed Forward Network\n",
    "        ffn_output = Dense(d_model * 4, activation=\"relu\")(attention_output)\n",
    "        ffn_output = Dense(d_model)(ffn_output)\n",
    "        ffn_output = Dropout(0.1)(ffn_output)\n",
    "        x = Add()([attention_output, ffn_output])  # Residual Connection\n",
    "        x = LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "    encoder_outputs = x  # 인코더 출력: (batch_size, input_length, d_model)\n",
    "\n",
    "    # 디코더 입력\n",
    "    decoder_inputs = RepeatVector(output_length)(encoder_outputs[:, -1, :])  # 마지막 타임스텝의 상태 복제 (batch_size, output_length, d_model)\n",
    "    y = decoder_inputs\n",
    "\n",
    "    # 디코더 블록\n",
    "    for _ in range(num_layers):\n",
    "        # Self-Attention in Decoder\n",
    "        self_attention = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(y, y)\n",
    "        self_attention = Dropout(0.1)(self_attention)\n",
    "        self_attention = Add()([y, self_attention])  # Residual Connection\n",
    "        self_attention = LayerNormalization(epsilon=1e-6)(self_attention)\n",
    "\n",
    "        # Cross-Attention with Encoder Outputs\n",
    "        cross_attention = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)(self_attention, encoder_outputs)\n",
    "        cross_attention = Dropout(0.1)(cross_attention)\n",
    "        cross_attention = Add()([self_attention, cross_attention])  # Residual Connection\n",
    "        cross_attention = LayerNormalization(epsilon=1e-6)(cross_attention)\n",
    "\n",
    "        # Feed Forward Network\n",
    "        ffn_output = Dense(d_model * 4, activation=\"relu\")(cross_attention)\n",
    "        ffn_output = Dense(d_model)(ffn_output)\n",
    "        ffn_output = Dropout(0.1)(ffn_output)\n",
    "        y = Add()([cross_attention, ffn_output])  # Residual Connection\n",
    "        y = LayerNormalization(epsilon=1e-6)(y)\n",
    "\n",
    "    # 디코더 출력\n",
    "    outputs = TimeDistributed(Dense(1, activation=\"linear\"))(y)  # (batch_size, output_length, 1)\n",
    "\n",
    "    # 모델 생성\n",
    "    return Model(inputs=encoder_inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ee3eaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 96, 6)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 96, 64)       448         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "positional_encoding_layer_1 (Po (None, 96, 64)       0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_2 (MultiHe (None, 96, 64)       66368       positional_encoding_layer_1[0][0]\n",
      "                                                                 positional_encoding_layer_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 96, 64)       0           multi_head_attention_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 96, 64)       0           positional_encoding_layer_1[0][0]\n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_4 (LayerNor (None, 96, 64)       128         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 96, 256)      16640       layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 96, 64)       16448       dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 96, 64)       0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 96, 64)       0           layer_normalization_4[0][0]      \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNor (None, 96, 64)       128         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_3 (MultiHe (None, 96, 64)       66368       layer_normalization_5[0][0]      \n",
      "                                                                 layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 96, 64)       0           multi_head_attention_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 96, 64)       0           layer_normalization_5[0][0]      \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_6 (LayerNor (None, 96, 64)       128         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 96, 256)      16640       layer_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 96, 64)       16448       dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 96, 64)       0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 96, 64)       0           layer_normalization_6[0][0]      \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_7 (LayerNor (None, 96, 64)       128         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (None, 64)           0           layer_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 720, 64)      0           tf.__operators__.getitem[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_4 (MultiHe (None, 720, 64)      66368       repeat_vector_1[0][0]            \n",
      "                                                                 repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 720, 64)      0           multi_head_attention_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 720, 64)      0           repeat_vector_1[0][0]            \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_8 (LayerNor (None, 720, 64)      128         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_5 (MultiHe (None, 720, 64)      66368       layer_normalization_8[0][0]      \n",
      "                                                                 layer_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 720, 64)      0           multi_head_attention_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 720, 64)      0           layer_normalization_8[0][0]      \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_9 (LayerNor (None, 720, 64)      128         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 720, 256)     16640       layer_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 720, 64)      16448       dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 720, 64)      0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 720, 64)      0           layer_normalization_9[0][0]      \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_10 (LayerNo (None, 720, 64)      128         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_6 (MultiHe (None, 720, 64)      66368       layer_normalization_10[0][0]     \n",
      "                                                                 layer_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 720, 64)      0           multi_head_attention_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 720, 64)      0           layer_normalization_10[0][0]     \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_11 (LayerNo (None, 720, 64)      128         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_7 (MultiHe (None, 720, 64)      66368       layer_normalization_11[0][0]     \n",
      "                                                                 layer_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 720, 64)      0           multi_head_attention_7[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 720, 64)      0           layer_normalization_11[0][0]     \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_12 (LayerNo (None, 720, 64)      128         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 720, 256)     16640       layer_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 720, 64)      16448       dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 720, 64)      0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 720, 64)      0           layer_normalization_12[0][0]     \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_13 (LayerNo (None, 720, 64)      128         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 720, 1)       65          layer_normalization_13[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 532,353\n",
      "Trainable params: 532,353\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "set_random_seed()\n",
    "\n",
    "# 모델 생성\n",
    "input_dim = X_train.shape[-1]   # 입력 데이터의 특성 차원\n",
    "\n",
    "d_model = 64\n",
    "num_heads = 4   # Multi-Head Attention에서의 head 개수\n",
    "num_layers = 2  # Transformer 블록의 레이어 수\n",
    "pos = 0\n",
    "\n",
    "# Transformer 모델 생성\n",
    "transformer_model = build_transformer(input_length, input_dim, output_length, d_model, num_heads, num_layers, pos)\n",
    "\n",
    "# 모델 컴파일\n",
    "transformer_model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "transformer_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6280f9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "52/52 [==============================] - 15s 237ms/step - loss: 0.5510 - mae: 0.4279 - val_loss: 0.0287 - val_mae: 0.1265\n",
      "Epoch 2/20\n",
      "52/52 [==============================] - 12s 227ms/step - loss: 0.0506 - mae: 0.1770 - val_loss: 0.0274 - val_mae: 0.1335\n",
      "Epoch 3/20\n",
      "52/52 [==============================] - 12s 228ms/step - loss: 0.0388 - mae: 0.1549 - val_loss: 0.0274 - val_mae: 0.1334\n",
      "Epoch 4/20\n",
      "52/52 [==============================] - 12s 230ms/step - loss: 0.0320 - mae: 0.1407 - val_loss: 0.0272 - val_mae: 0.1321\n",
      "Epoch 5/20\n",
      "52/52 [==============================] - 12s 227ms/step - loss: 0.0296 - mae: 0.1353 - val_loss: 0.0268 - val_mae: 0.1300\n",
      "Epoch 6/20\n",
      "52/52 [==============================] - 12s 233ms/step - loss: 0.0289 - mae: 0.1336 - val_loss: 0.0267 - val_mae: 0.1281\n",
      "Epoch 7/20\n",
      "52/52 [==============================] - 12s 234ms/step - loss: 0.0284 - mae: 0.1327 - val_loss: 0.0267 - val_mae: 0.1276\n",
      "Epoch 8/20\n",
      "52/52 [==============================] - 12s 237ms/step - loss: 0.0277 - mae: 0.1312 - val_loss: 0.0283 - val_mae: 0.1373\n",
      "Epoch 9/20\n",
      "52/52 [==============================] - 12s 233ms/step - loss: 0.0272 - mae: 0.1303 - val_loss: 0.0265 - val_mae: 0.1306\n",
      "Epoch 10/20\n",
      "52/52 [==============================] - 12s 228ms/step - loss: 0.0267 - mae: 0.1295 - val_loss: 0.0259 - val_mae: 0.1291\n",
      "Epoch 11/20\n",
      "52/52 [==============================] - 12s 228ms/step - loss: 0.0262 - mae: 0.1287 - val_loss: 0.0274 - val_mae: 0.1347\n",
      "Epoch 12/20\n",
      "52/52 [==============================] - 12s 228ms/step - loss: 0.0258 - mae: 0.1281 - val_loss: 0.0257 - val_mae: 0.1243\n",
      "Epoch 13/20\n",
      "52/52 [==============================] - 12s 228ms/step - loss: 0.0245 - mae: 0.1248 - val_loss: 0.0228 - val_mae: 0.1208\n",
      "Epoch 14/20\n",
      "52/52 [==============================] - 12s 229ms/step - loss: 0.0210 - mae: 0.1139 - val_loss: 0.0180 - val_mae: 0.1066\n",
      "Epoch 15/20\n",
      "52/52 [==============================] - 12s 229ms/step - loss: 0.0185 - mae: 0.1067 - val_loss: 0.0188 - val_mae: 0.1083\n",
      "Epoch 16/20\n",
      "52/52 [==============================] - 12s 228ms/step - loss: 0.0164 - mae: 0.1007 - val_loss: 0.0149 - val_mae: 0.0957\n",
      "Epoch 17/20\n",
      "52/52 [==============================] - 12s 228ms/step - loss: 0.0163 - mae: 0.1002 - val_loss: 0.0195 - val_mae: 0.1091\n",
      "Epoch 18/20\n",
      "52/52 [==============================] - 12s 230ms/step - loss: 0.0164 - mae: 0.1004 - val_loss: 0.0179 - val_mae: 0.1056\n",
      "Epoch 19/20\n",
      "52/52 [==============================] - 12s 229ms/step - loss: 0.0156 - mae: 0.0980 - val_loss: 0.0153 - val_mae: 0.0975\n",
      "Epoch 20/20\n",
      "52/52 [==============================] - 12s 230ms/step - loss: 0.0142 - mae: 0.0938 - val_loss: 0.0125 - val_mae: 0.0885\n",
      "104/104 [==============================] - 2s 17ms/step - loss: 0.0125 - mae: 0.0885\n",
      "Test Loss: 0.012500489130616188, Test MAE: 0.08852755278348923\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "history = transformer_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=20,\n",
    "    batch_size=256\n",
    ")\n",
    "\n",
    "# 평가\n",
    "loss, mae = transformer_model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}, Test MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5c6904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df7dd5cb",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1a94ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_lstm(input_length, input_dim, output_length, lstm_units):\n",
    "    \"\"\"\n",
    "    LSTM 기반 시계열 예측 모델\n",
    "    Args:\n",
    "        input_length: 입력 시퀀스 길이\n",
    "        input_dim: 입력 데이터 차원 (특성 수)\n",
    "        output_length: 출력 시퀀스 길이\n",
    "        lstm_units: LSTM 유닛 수\n",
    "    Returns:\n",
    "        Model: 생성된 Keras 모델\n",
    "    \"\"\"\n",
    "    # 입력 레이어\n",
    "    inputs = Input(shape=(input_length, input_dim))  # (batch_size, input_length, input_dim)\n",
    "    \n",
    "    # LSTM 인코더\n",
    "    x = LSTM(lstm_units, return_sequences=False)(inputs)  # (batch_size, lstm_units)\n",
    "    \n",
    "    # RepeatVector로 디코더 입력 생성\n",
    "    x = RepeatVector(output_length)(x)  # (batch_size, output_length, lstm_units)\n",
    "    \n",
    "    # LSTM 디코더\n",
    "    x = LSTM(lstm_units, return_sequences=True)(x)  # (batch_size, output_length, lstm_units)\n",
    "    \n",
    "    # TimeDistributed를 사용한 Dense 출력\n",
    "    outputs = TimeDistributed(Dense(1))(x)  # (batch_size, output_length, 1)\n",
    "    \n",
    "    return Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bef8e04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 96, 6)]           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                18176     \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 720, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 720, 64)           33024     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 720, 1)            65        \n",
      "=================================================================\n",
      "Total params: 51,265\n",
      "Trainable params: 51,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "52/52 [==============================] - 7s 85ms/step - loss: 0.0340 - mae: 0.1433 - val_loss: 0.0259 - val_mae: 0.1280\n",
      "Epoch 2/20\n",
      "52/52 [==============================] - 4s 74ms/step - loss: 0.0256 - mae: 0.1270 - val_loss: 0.0258 - val_mae: 0.1267\n",
      "Epoch 3/20\n",
      "52/52 [==============================] - 4s 75ms/step - loss: 0.0255 - mae: 0.1268 - val_loss: 0.0258 - val_mae: 0.1264\n",
      "Epoch 4/20\n",
      "52/52 [==============================] - 4s 75ms/step - loss: 0.0255 - mae: 0.1266 - val_loss: 0.0257 - val_mae: 0.1262\n",
      "Epoch 5/20\n",
      "52/52 [==============================] - 4s 74ms/step - loss: 0.0254 - mae: 0.1264 - val_loss: 0.0257 - val_mae: 0.1274\n",
      "Epoch 6/20\n",
      "52/52 [==============================] - 4s 74ms/step - loss: 0.0253 - mae: 0.1261 - val_loss: 0.0255 - val_mae: 0.1263\n",
      "Epoch 7/20\n",
      "52/52 [==============================] - 4s 74ms/step - loss: 0.0252 - mae: 0.1258 - val_loss: 0.0259 - val_mae: 0.1279\n",
      "Epoch 8/20\n",
      "52/52 [==============================] - 4s 75ms/step - loss: 0.0255 - mae: 0.1264 - val_loss: 0.0254 - val_mae: 0.1263\n",
      "Epoch 9/20\n",
      "52/52 [==============================] - 4s 75ms/step - loss: 0.0249 - mae: 0.1253 - val_loss: 0.0248 - val_mae: 0.1242\n",
      "Epoch 10/20\n",
      "52/52 [==============================] - 4s 75ms/step - loss: 0.0236 - mae: 0.1214 - val_loss: 0.0257 - val_mae: 0.1274\n",
      "Epoch 11/20\n",
      "52/52 [==============================] - 4s 75ms/step - loss: 0.0254 - mae: 0.1261 - val_loss: 0.0257 - val_mae: 0.1241\n",
      "Epoch 12/20\n",
      "52/52 [==============================] - 4s 75ms/step - loss: 0.0249 - mae: 0.1248 - val_loss: 0.0246 - val_mae: 0.1230\n",
      "Epoch 13/20\n",
      "52/52 [==============================] - 4s 74ms/step - loss: 0.0237 - mae: 0.1203 - val_loss: 0.0248 - val_mae: 0.1211\n",
      "Epoch 14/20\n",
      "52/52 [==============================] - 4s 74ms/step - loss: 0.0221 - mae: 0.1156 - val_loss: 0.0223 - val_mae: 0.1175\n",
      "Epoch 15/20\n",
      "52/52 [==============================] - 4s 75ms/step - loss: 0.0186 - mae: 0.1051 - val_loss: 0.0179 - val_mae: 0.1030\n",
      "Epoch 16/20\n",
      "52/52 [==============================] - 4s 74ms/step - loss: 0.0213 - mae: 0.1126 - val_loss: 0.0230 - val_mae: 0.1176\n",
      "Epoch 17/20\n",
      "52/52 [==============================] - 4s 75ms/step - loss: 0.0199 - mae: 0.1068 - val_loss: 0.0184 - val_mae: 0.1022\n",
      "Epoch 18/20\n",
      "52/52 [==============================] - 4s 75ms/step - loss: 0.0188 - mae: 0.1052 - val_loss: 0.0156 - val_mae: 0.0976\n",
      "Epoch 19/20\n",
      "52/52 [==============================] - 4s 75ms/step - loss: 0.0158 - mae: 0.0970 - val_loss: 0.0138 - val_mae: 0.0895\n",
      "Epoch 20/20\n",
      "52/52 [==============================] - 4s 74ms/step - loss: 0.0130 - mae: 0.0888 - val_loss: 0.0115 - val_mae: 0.0842\n",
      "104/104 [==============================] - 1s 13ms/step - loss: 0.0115 - mae: 0.0842\n",
      "Test Loss: 0.01148737408220768, Test MAE: 0.08422904461622238\n"
     ]
    }
   ],
   "source": [
    "set_random_seed()\n",
    "\n",
    "# 모델 생성\n",
    "lstm_units = 64  # LSTM 유닛 수\n",
    "lstm_model = build_lstm(input_length, input_dim, output_length, lstm_units)\n",
    "\n",
    "# 모델 컴파일\n",
    "lstm_model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "lstm_model.summary()\n",
    "\n",
    "# 모델 학습\n",
    "history = lstm_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=20,\n",
    "    batch_size=256\n",
    ")\n",
    "\n",
    "# 모델 평가\n",
    "loss, mae = lstm_model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}, Test MAE: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2106ee81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
